{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **기획**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <기획 가이드>\n",
    "> #### 현업 적용 문제 정의\n",
    "(공유 가능한 선에서 업무를 소개해 주세요)\n",
    "- **요구사항 확인 :** 현업에서의 분석 요구사항, 요구사항이 나오게 된 배경 등 과 같은 실제 현업의 문제점 작성.\n",
    "- **문제 범위 설정 :** 인텐시브 과정 내 가능한 수준인가, 분석 범위 및 계획 등과 같은 범위를 설정.\n",
    "- **문제 정의 도출 :** 위 내용을 바탕으로 해결하고 싶은 문제(가설) 정의.<br> (main 정의 후 main을 해결하기 위한 sub 문제 2-3개)\n",
    "\n",
    "> #### 데이터 수집 방안 및 사용 데이터 정의\n",
    "- **데이터 확보 방법 :** 사내 DB 추출, 웹데이터 크롤링 등 확보 방법을 작성해 주세요.\n",
    "- **활용 데이터 정의 :** 데이터 소스(사내 시스템명, 외부 사이트 URL 등), 데이터 유형(정형, 비정형_텍스트, 이미지, 영상 등), Feature, 형태(확장자, shape, size, count) 등 데이터에 관한 설명<br>\n",
    "\n",
    "> #### 분석 방향 설정\n",
    "- **분석 시 예상되는 어려움 :** 논리적 추론을 통해 문제를 해결해 나가는 과정에서 짐작되는 어려운 부분을 작성.\n",
    "- **문제 해결을 위한 모델 사용 방법 :** 문제에 적합한 모델을 어떻게 구성해 나갈 것인지 작성."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [배경 설명 & 요구사항 확인]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "![플라즈마 이미지](image/project/plasma.jpg)\n",
    "\n",
    "> ### 배경\n",
    "\n",
    "- 플라즈마 사용 공정 설비에서 문제 발생할 경우, 플라즈마 광 신호 세기가 불안정해집니다.\n",
    "\n",
    "- 제가 하는 업무는 이러한 플라즈마 이상 신호를 진단하기 위해, 플라즈마 광 신호를 실시간 측정하는 센서를 개발하고 있습니다.\n",
    "\n",
    "  ※ 플라즈마에서 방출된 photon을 electron으로 변환하여, PMT 소자를 이용해 플라즈마 광 신호 세기를 측정하는 원리입니다.\n",
    "\n",
    "> ### 요구사항\n",
    "\n",
    "- 플라즈마 광 신호 데이터 양이 너무 많아 분석하는데 시간이 오래 걸립니다. (50,000 points/s)\n",
    "\n",
    "- 플라즈마 이상 신호를 자동으로 진단하는 모델을 개발해서 이상 신호를 조기에 감지하는 것을 목표로 합니다.\n",
    "\n",
    "- 최종적으로 엔지니어에게 알람을 제공하는 시스템 구축해, 플라즈마 공정 설비 안정성을 유지하는 것을 목표로 합니다.\n",
    "\n",
    "> ### 문제 범위 설정\n",
    "\n",
    "- 주요 목표는 플라즈마 광 신호를 실시간 측정하는 센서로부터 생성된 데이터를 사용하여 이상 신호 진단하는 모델을 개발하는 것입니다.\n",
    "\n",
    "> ### 문제 정의 도출\n",
    "\n",
    "- Main 문제 정의: 센서 데이터 기반으로 이상 신호를 자동으로 진단하는 자동 이상 진단 모델을 개발합니다.\n",
    "\n",
    "- Sub 문제:\n",
    "\n",
    "  1. 플라즈마 광 신호의 정상 범위 정의\n",
    "  2. 정상 범위를 벗어나는 이상 신호 정의\n",
    "  3. 정상 신호와 이상 신호 식별하는 알고리즘 개발\n",
    "  4. 개발 모델 검증, 성능 평가 지표 설정\n",
    "  5. 테스트 후 모델 조정 및 개선\n",
    "\n",
    "> ### 데이터 확보 방법\n",
    "\n",
    "- 센서 데이터 사외 반출이 안 되어, 실제 신호 데이터와 최대한 유사하게 base signal을 만들고 noise와 이상 신호를 추가하여 직접 만들었습니다. (make_signal.ipynb 참고)\n",
    "\n",
    "> ### 활용 데이터 정의\n",
    "\n",
    "- 데이터 소스: 플라즈마 광 센서 데이터\n",
    "\n",
    "- 데이터 유형:\n",
    "\n",
    "   1. 정형 데이터이며, 2차원 배열 형식의 숫자 데이터\n",
    "\n",
    "- Feature:\n",
    "\n",
    "   1. Feature는 센서 데이터의 인덱스 (시간 순, 마지막 column 전까지)\n",
    "   2. 마지막 column은 target column\n",
    "   3. target column의 값은 0(정상), 1, 2, 3, 4, 5, 6(이상치/흔들림, 구간별)\n",
    "\n",
    "- 형태:\n",
    "   1. pickle 파일\n",
    "   2. 총 4가지의 다른 유형의 신호 데이터를 가짐\n",
    "   3. 각 파일은 13,600 건의 레코드를 포함\n",
    "   4. column 개수는 신호 길이에 따라 다름\n",
    "\n",
    "> ### 분석시 예상되는 어려움\n",
    "\n",
    "- 고차원 데이터: 데이터 양이 많아 리소스가 많이 투입되고 전처리 하기 어려움 (shape: 13,600 x 1,000, 4개의 파일)\n",
    "\n",
    "- 이상치 데이터 불균형: 정상 신호 1,000 개 중 이상치 1개 (0.1% 이하)\n",
    "\n",
    "- 클래스 불균형: 정상 신호와 이상 신호간 비율이 불균형 (10,000 vs 3,600)\n",
    "\n",
    "- 센서 노이즈 및 오차: 빛의 신호가 약해질 수록 상대적으로 노이즈가 커져 모델 성능 저하 가능성 존재\n",
    "\n",
    "- 모델 설명 가능성: 설득해야 하는 위치 상, 딥러닝 같이 설명 불가능한 모델은 사용이 어려움\n",
    "\n",
    "> ### 분석 방향 설정\n",
    "\n",
    "- 데이터 전처리\n",
    "\n",
    "   1. 데이터 탐색\n",
    "      - 데이터 구조를 파악하여 특징 확인 (head, columns, unique, describe, info)\n",
    "      - 이상치나 노이즈를 확인하기 위해 데이터 분포 시각화 및 기초 통계량 확인\n",
    "   2. 데이터 전처리\n",
    "      - 결측치가 존재하는 경우 해당 행은 근처 값의 평균으로 fill\n",
    "   3. 데이터 특성 선택\n",
    "      - 모두 동일한 값을 가지는 column 제거 (특정 feature가 모든 샘플에 같은 상수 값을 가짐)\n",
    "      - column끼리 비교하여 같은 값을 가지는 column들이 있다면 제거\n",
    "\n",
    "- 데이터 시각화\n",
    "\n",
    "   1. target 값 별로 어떤 종류의 이상 신호인지 확인\n",
    "      - 각 특성 분포를 시각화하여 데이터 특성 파악\n",
    "      - 정상 신호와 이상 신호 간의 클래스 비율 확인하여 불균형 있는지 확인\n",
    "   2. target column의 value_counts 이용, 정상치와 이상치 비율 확인\n",
    "\n",
    "- 모델 선택과 학습\n",
    "\n",
    "   1. 모델 선택\n",
    "      - 설명 불가능한 딥러닝 모델 보다는 설명할 수 있는 머신러닝 모델을 우선 고려\n",
    "      - target 데이터가 있기 때문에 분류해주는 머신러닝 모델 평갸 (강사님이 다 돌려보래서 배운 분류 모델 전부 돌릴 예정)\n",
    "         1. KNN\n",
    "         2. Logistic Regression\n",
    "         3. Naive Bayes\n",
    "         4. Decision Tree\n",
    "         5. Support Vector Machine\n",
    "         6. Random Forest\n",
    "         7. AdaBoost\n",
    "         8. GradientBoosting\n",
    "         9. LDA\n",
    "      - 위에서 나온 결과를 토대로 앙상블 모델도 평가\n",
    "         1. Voting\n",
    "         2. Bagging\n",
    "         3. Stacking\n",
    "   2. 모델 학습\n",
    "      - 데이터를 학습, 검증, 테스트 셋으로 나누어서 학습\n",
    "\n",
    "- 모델 평가와 해석\n",
    "\n",
    "   1. 성능 평가\n",
    "      - 모델의 성능을 평가하기 위해 accuracy, prcision, recall, f1 score, confusion matrix 등을 사용\n",
    "   2. 모델 해석\n",
    "      - 모델의 의사 결정 과정을 해석하기 위해 모델의 특성 중요도를 확인하고, SHAP(SHapley Additive exPlanations) 등의 기법을 사용하여 모델의 동작을 설명\n",
    "\n",
    "- 모델 최적화와 향상\n",
    "\n",
    "   1. 모델 개선\n",
    "      - Cross validation을 이용하여 모델 평가\n",
    "      - GridSearchCV를 이용하여 모델 별 하이퍼 파라미터 튜닝을 통한 모델 성능 최적화\n",
    "      - 불필요한 특성 탐색 후, 제거\n",
    "      - 앙상블 기법 사용해서 최적화 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **준비**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <준비 가이드>\n",
    "#### 데이터 수집 및 로드\n",
    "- 문제 해결에 필요한 데이터를 수집 및 로드.\n",
    "\n",
    "#### 데이터 전처리\n",
    "- 결측치 처리, 이상치 처리, feature scale 등 데이터 정제.\n",
    "- 데이터의 품질을 향상시키는 것이 중요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [데이터 수집 및 로드]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사내 DB에서 SQL 쿼리를 사용하여 고객 구매 이력, 상품 정보, 고객 행동 로그 데이터를 추출합니다.\n",
    "데이터는 CSV 형식으로 저장되며, Python의 pandas 라이브러리를 사용하여 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_signal1 = pd.read_pickle('./data/signal/data_1.pkl')\n",
    "# df_signal2 = pd.read_pickle('./data/signal/data_2.pkl')\n",
    "# df_signal3 = pd.read_pickle('./data/signal/data_3.pkl')\n",
    "# df_signal5 = pd.read_pickle('./data/signal/data_5.pkl')\n",
    "\n",
    "df = pd.read_pickle('./data/signal/data_1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [데이터 전처리]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불러온 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>963</th>\n",
       "      <th>964</th>\n",
       "      <th>965</th>\n",
       "      <th>966</th>\n",
       "      <th>967</th>\n",
       "      <th>968</th>\n",
       "      <th>969</th>\n",
       "      <th>970</th>\n",
       "      <th>971</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000848</td>\n",
       "      <td>0.114165</td>\n",
       "      <td>0.115450</td>\n",
       "      <td>0.116349</td>\n",
       "      <td>0.115052</td>\n",
       "      <td>0.115237</td>\n",
       "      <td>0.116666</td>\n",
       "      <td>0.115224</td>\n",
       "      <td>0.114603</td>\n",
       "      <td>0.112557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110770</td>\n",
       "      <td>0.112873</td>\n",
       "      <td>0.111688</td>\n",
       "      <td>0.112707</td>\n",
       "      <td>0.113912</td>\n",
       "      <td>0.112011</td>\n",
       "      <td>0.115797</td>\n",
       "      <td>0.113945</td>\n",
       "      <td>0.117518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000765</td>\n",
       "      <td>0.116459</td>\n",
       "      <td>0.116574</td>\n",
       "      <td>0.115264</td>\n",
       "      <td>0.114735</td>\n",
       "      <td>0.116400</td>\n",
       "      <td>0.115822</td>\n",
       "      <td>0.115286</td>\n",
       "      <td>0.113594</td>\n",
       "      <td>0.115990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111750</td>\n",
       "      <td>0.111584</td>\n",
       "      <td>0.112824</td>\n",
       "      <td>0.112329</td>\n",
       "      <td>0.113641</td>\n",
       "      <td>0.113575</td>\n",
       "      <td>0.113880</td>\n",
       "      <td>0.114035</td>\n",
       "      <td>0.116569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001242</td>\n",
       "      <td>0.115493</td>\n",
       "      <td>0.114507</td>\n",
       "      <td>0.114148</td>\n",
       "      <td>0.114146</td>\n",
       "      <td>0.116524</td>\n",
       "      <td>0.116538</td>\n",
       "      <td>0.113990</td>\n",
       "      <td>0.115798</td>\n",
       "      <td>0.112641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110778</td>\n",
       "      <td>0.112879</td>\n",
       "      <td>0.109856</td>\n",
       "      <td>0.111060</td>\n",
       "      <td>0.113145</td>\n",
       "      <td>0.112905</td>\n",
       "      <td>0.113081</td>\n",
       "      <td>0.114317</td>\n",
       "      <td>0.113436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.115711</td>\n",
       "      <td>0.114697</td>\n",
       "      <td>0.115865</td>\n",
       "      <td>0.114772</td>\n",
       "      <td>0.115833</td>\n",
       "      <td>0.114890</td>\n",
       "      <td>0.115611</td>\n",
       "      <td>0.111572</td>\n",
       "      <td>0.115685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110463</td>\n",
       "      <td>0.112231</td>\n",
       "      <td>0.111893</td>\n",
       "      <td>0.112992</td>\n",
       "      <td>0.113005</td>\n",
       "      <td>0.113656</td>\n",
       "      <td>0.113511</td>\n",
       "      <td>0.112386</td>\n",
       "      <td>0.114992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000284</td>\n",
       "      <td>0.114454</td>\n",
       "      <td>0.113036</td>\n",
       "      <td>0.117318</td>\n",
       "      <td>0.114204</td>\n",
       "      <td>0.113921</td>\n",
       "      <td>0.115200</td>\n",
       "      <td>0.115883</td>\n",
       "      <td>0.114302</td>\n",
       "      <td>0.116021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110461</td>\n",
       "      <td>0.110477</td>\n",
       "      <td>0.110693</td>\n",
       "      <td>0.112163</td>\n",
       "      <td>0.113123</td>\n",
       "      <td>0.114545</td>\n",
       "      <td>0.112851</td>\n",
       "      <td>0.115291</td>\n",
       "      <td>0.114702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 973 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.000848  0.114165  0.115450  0.116349  0.115052  0.115237  0.116666   \n",
       "1 -0.000765  0.116459  0.116574  0.115264  0.114735  0.116400  0.115822   \n",
       "2 -0.001242  0.115493  0.114507  0.114148  0.114146  0.116524  0.116538   \n",
       "3  0.000915  0.115711  0.114697  0.115865  0.114772  0.115833  0.114890   \n",
       "4 -0.000284  0.114454  0.113036  0.117318  0.114204  0.113921  0.115200   \n",
       "\n",
       "          7         8         9  ...       963       964       965       966  \\\n",
       "0  0.115224  0.114603  0.112557  ...  0.110770  0.112873  0.111688  0.112707   \n",
       "1  0.115286  0.113594  0.115990  ...  0.111750  0.111584  0.112824  0.112329   \n",
       "2  0.113990  0.115798  0.112641  ...  0.110778  0.112879  0.109856  0.111060   \n",
       "3  0.115611  0.111572  0.115685  ...  0.110463  0.112231  0.111893  0.112992   \n",
       "4  0.115883  0.114302  0.116021  ...  0.110461  0.110477  0.110693  0.112163   \n",
       "\n",
       "        967       968       969       970       971  target  \n",
       "0  0.113912  0.112011  0.115797  0.113945  0.117518       0  \n",
       "1  0.113641  0.113575  0.113880  0.114035  0.116569       0  \n",
       "2  0.113145  0.112905  0.113081  0.114317  0.113436       0  \n",
       "3  0.113005  0.113656  0.113511  0.112386  0.114992       0  \n",
       "4  0.113123  0.114545  0.112851  0.115291  0.114702       0  \n",
       "\n",
       "[5 rows x 973 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([       0,        1,        2,        3,        4,        5,        6,\n",
       "              7,        8,        9,\n",
       "       ...\n",
       "            963,      964,      965,      966,      967,      968,      969,\n",
       "            970,      971, 'target'],\n",
       "      dtype='object', length=973)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13600 entries, 0 to 13599\n",
      "Columns: 973 entries, 0 to target\n",
      "dtypes: float64(972), int32(1)\n",
      "memory usage: 100.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape: (13600, 973)\n",
      "feature: float64 type, 972 columns\n",
      "target: int32 type, 1 column\n"
     ]
    }
   ],
   "source": [
    "print(f'df.shape: {df.shape}')\n",
    "print(f'feature: float64 type, 972 columns')\n",
    "print(f'target: int32 type, 1 column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>963</th>\n",
       "      <th>964</th>\n",
       "      <th>965</th>\n",
       "      <th>966</th>\n",
       "      <th>967</th>\n",
       "      <th>968</th>\n",
       "      <th>969</th>\n",
       "      <th>970</th>\n",
       "      <th>971</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13600.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "      <td>13600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.115502</td>\n",
       "      <td>0.115071</td>\n",
       "      <td>0.115096</td>\n",
       "      <td>0.114876</td>\n",
       "      <td>0.115327</td>\n",
       "      <td>0.115252</td>\n",
       "      <td>0.114406</td>\n",
       "      <td>0.114125</td>\n",
       "      <td>0.114067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110846</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>0.111264</td>\n",
       "      <td>0.111951</td>\n",
       "      <td>0.113116</td>\n",
       "      <td>0.112931</td>\n",
       "      <td>0.113279</td>\n",
       "      <td>0.113248</td>\n",
       "      <td>0.114172</td>\n",
       "      <td>0.926471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>1.776680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.003964</td>\n",
       "      <td>0.111708</td>\n",
       "      <td>0.110712</td>\n",
       "      <td>0.110847</td>\n",
       "      <td>0.110822</td>\n",
       "      <td>0.110934</td>\n",
       "      <td>0.111248</td>\n",
       "      <td>0.110435</td>\n",
       "      <td>0.110314</td>\n",
       "      <td>0.110178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106717</td>\n",
       "      <td>0.107367</td>\n",
       "      <td>0.107439</td>\n",
       "      <td>0.107801</td>\n",
       "      <td>0.109096</td>\n",
       "      <td>0.108785</td>\n",
       "      <td>0.109179</td>\n",
       "      <td>0.109285</td>\n",
       "      <td>0.109072</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000706</td>\n",
       "      <td>0.114818</td>\n",
       "      <td>0.114365</td>\n",
       "      <td>0.114394</td>\n",
       "      <td>0.114180</td>\n",
       "      <td>0.114644</td>\n",
       "      <td>0.114543</td>\n",
       "      <td>0.113714</td>\n",
       "      <td>0.113425</td>\n",
       "      <td>0.113369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110156</td>\n",
       "      <td>0.110578</td>\n",
       "      <td>0.110569</td>\n",
       "      <td>0.111253</td>\n",
       "      <td>0.112412</td>\n",
       "      <td>0.112242</td>\n",
       "      <td>0.112583</td>\n",
       "      <td>0.112547</td>\n",
       "      <td>0.113490</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.115505</td>\n",
       "      <td>0.115073</td>\n",
       "      <td>0.115097</td>\n",
       "      <td>0.114877</td>\n",
       "      <td>0.115332</td>\n",
       "      <td>0.115254</td>\n",
       "      <td>0.114410</td>\n",
       "      <td>0.114127</td>\n",
       "      <td>0.114076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110848</td>\n",
       "      <td>0.111264</td>\n",
       "      <td>0.111258</td>\n",
       "      <td>0.111950</td>\n",
       "      <td>0.113115</td>\n",
       "      <td>0.112923</td>\n",
       "      <td>0.113278</td>\n",
       "      <td>0.113249</td>\n",
       "      <td>0.114166</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.116185</td>\n",
       "      <td>0.115774</td>\n",
       "      <td>0.115809</td>\n",
       "      <td>0.115576</td>\n",
       "      <td>0.116017</td>\n",
       "      <td>0.115958</td>\n",
       "      <td>0.115092</td>\n",
       "      <td>0.114826</td>\n",
       "      <td>0.114772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111539</td>\n",
       "      <td>0.111975</td>\n",
       "      <td>0.111961</td>\n",
       "      <td>0.112652</td>\n",
       "      <td>0.113815</td>\n",
       "      <td>0.113629</td>\n",
       "      <td>0.113975</td>\n",
       "      <td>0.113938</td>\n",
       "      <td>0.114853</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.119497</td>\n",
       "      <td>0.118773</td>\n",
       "      <td>0.119534</td>\n",
       "      <td>0.119323</td>\n",
       "      <td>0.118877</td>\n",
       "      <td>0.119259</td>\n",
       "      <td>0.118845</td>\n",
       "      <td>0.117988</td>\n",
       "      <td>0.118104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115066</td>\n",
       "      <td>0.115381</td>\n",
       "      <td>0.115415</td>\n",
       "      <td>0.115564</td>\n",
       "      <td>0.116996</td>\n",
       "      <td>0.116675</td>\n",
       "      <td>0.117975</td>\n",
       "      <td>0.117287</td>\n",
       "      <td>0.118145</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 973 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  13600.000000  13600.000000  13600.000000  13600.000000  13600.000000   \n",
       "mean       0.000008      0.115502      0.115071      0.115096      0.114876   \n",
       "std        0.001034      0.001025      0.001032      0.001035      0.001037   \n",
       "min       -0.003964      0.111708      0.110712      0.110847      0.110822   \n",
       "25%       -0.000706      0.114818      0.114365      0.114394      0.114180   \n",
       "50%       -0.000001      0.115505      0.115073      0.115097      0.114877   \n",
       "75%        0.000706      0.116185      0.115774      0.115809      0.115576   \n",
       "max        0.003925      0.119497      0.118773      0.119534      0.119323   \n",
       "\n",
       "                  5             6             7             8             9  \\\n",
       "count  13600.000000  13600.000000  13600.000000  13600.000000  13600.000000   \n",
       "mean       0.115327      0.115252      0.114406      0.114125      0.114067   \n",
       "std        0.001026      0.001043      0.001026      0.001031      0.001028   \n",
       "min        0.110934      0.111248      0.110435      0.110314      0.110178   \n",
       "25%        0.114644      0.114543      0.113714      0.113425      0.113369   \n",
       "50%        0.115332      0.115254      0.114410      0.114127      0.114076   \n",
       "75%        0.116017      0.115958      0.115092      0.114826      0.114772   \n",
       "max        0.118877      0.119259      0.118845      0.117988      0.118104   \n",
       "\n",
       "       ...           963           964           965           966  \\\n",
       "count  ...  13600.000000  13600.000000  13600.000000  13600.000000   \n",
       "mean   ...      0.110846      0.111275      0.111264      0.111951   \n",
       "std    ...      0.001023      0.001030      0.001034      0.001026   \n",
       "min    ...      0.106717      0.107367      0.107439      0.107801   \n",
       "25%    ...      0.110156      0.110578      0.110569      0.111253   \n",
       "50%    ...      0.110848      0.111264      0.111258      0.111950   \n",
       "75%    ...      0.111539      0.111975      0.111961      0.112652   \n",
       "max    ...      0.115066      0.115381      0.115415      0.115564   \n",
       "\n",
       "                967           968           969           970           971  \\\n",
       "count  13600.000000  13600.000000  13600.000000  13600.000000  13600.000000   \n",
       "mean       0.113116      0.112931      0.113279      0.113248      0.114172   \n",
       "std        0.001027      0.001037      0.001029      0.001031      0.001022   \n",
       "min        0.109096      0.108785      0.109179      0.109285      0.109072   \n",
       "25%        0.112412      0.112242      0.112583      0.112547      0.113490   \n",
       "50%        0.113115      0.112923      0.113278      0.113249      0.114166   \n",
       "75%        0.113815      0.113629      0.113975      0.113938      0.114853   \n",
       "max        0.116996      0.116675      0.117975      0.117287      0.118145   \n",
       "\n",
       "             target  \n",
       "count  13600.000000  \n",
       "mean       0.926471  \n",
       "std        1.776680  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        1.000000  \n",
       "max        6.000000  \n",
       "\n",
       "[8 rows x 973 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_null_columns(df):\n",
    "    null_sum = df.isnull().sum()\n",
    "    null_columns = null_sum[null_sum != 0]\n",
    "    print('제거할 열: ', null_columns)\n",
    "    return null_columns\n",
    "\n",
    "report_null_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모두 같은 상수 값을 가지는 column 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_uniform_columns(df):\n",
    "    columns_to_remove = [col for col in df.columns if df[col].nunique() == 1]\n",
    "    print('제거된 열: ', columns_to_remove)\n",
    "    return df.drop(columns=columns_to_remove)\n",
    "\n",
    "df = remove_uniform_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "column끼리 비교하여 같은 값을 가지는 column들이 있다면 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicate_columns(df):\n",
    "    df_T = df.T.drop_duplicates().T\n",
    "    columns_to_remove = df.columns.difference(df_T.columns)\n",
    "    print('제거된 열: ', columns_to_remove.tolist())\n",
    "    return df_T\n",
    "\n",
    "df = check_duplicate_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <EDA 가이드>\n",
    "- 데이터의 구조, 패턴, 이상치, 상관 관계 등을 파악\n",
    "- 시각화 도구를 사용하여 데이터를 분석\n",
    "- 모델의 성능을 향상시키기 위해 피처를 선택, 변환, 생성\n",
    "- 데이터의 정보를 최대한 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matplotlib과 seaborn 라이브러리를 사용하여 데이터의 분포, 상관 관계를 시각화합니다.\n",
    "고객의 구매 패턴, 상품 카테고리별 판매량 등 주요 인사이트를 도출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target (0, 1, 2, 3, 4, 5, 6) 별로 5개씩 sampling 해서 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5\n",
    "unique_targets = df['target'].unique()\n",
    "n_unique_targets = len(unique_targets)\n",
    "\n",
    "fig, axes = plt.subplots(n_unique_targets, num_samples, figsize=(15, 10))\n",
    "for idx, target in enumerate(unique_targets):\n",
    "    df_sub = df[df['target'] == target].sample(num_samples)\n",
    "    for j in range(num_samples):\n",
    "        ax = axes[idx, j]\n",
    "        ax.plot(df_sub.iloc[j, :-1].values)\n",
    "        ax.set_title(f'target: {target}, sample: {j+1}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target (0, 1, 2, 3, 4, 5, 6) 별로 count 개수 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "target_value_counts = df['target'].value_counts()\n",
    "print(target_value_counts)\n",
    "plt.pie(target_value_counts, labels=target_value_counts.index, explode=([0.1]*len(target_value_counts)), autopct='%1.1f%%', colors=cm.Set3.colors, startangle=90, counterclock=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 시각화 결과를 통해 다음과 같은 패턴을 확인할 수 있었습니다.\n",
    "\n",
    "`bill_length_mm`과 `bill_depth_mm`로 Scatter plot를 그려볼 시 각 종별로 일부 데이터를 제외하고 군집이 잘 형성됨을 확인하였습니다.\n",
    "\n",
    "- **Adelie:** 다른 펭귄 보다 bill_length가 작고, Chinstrap 펭귄과  bill_depth가 비슷하게 분포한다.\n",
    "- **Chinstrap:** Adelie 펭귄 보다 bill_length가 크고, Gentoo 펭귄과 bill_depth가 비슷하게 분포한다.\n",
    "- **Gentoo:**  Chinstrap 펭귄과 bill_length가 비슷하고, 다른 펭귄 보다 bill_depth가 작게 분포한다.\n",
    "\n",
    "\n",
    "종과 상관없이 수컷 팽귄의 `bill_length`와 `bill_depth`이 암컷보다 선형적으로 커진다는 것을 확인할 수 있었으며,\n",
    "<br>`body_mass`를 통해 Gentoo 펭귄이 다른 종보다 큰 몸집을 갖는다는 것을 확인하였습니다.\n",
    "\n",
    "이 내용을 기반으로 종별 bill_length, bill_depth 등 각 컬럼의 Number Summary를 확인 하고자 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- target 0 : 정상 신호 (10,000개, 73.5%)\n",
    "- target 1, 2, 3: 불규칙적인 튀는 신호 (구간 별, 각 600개, 4.4%)\n",
    "- target 4, 5, 6: 노이즈가 섞인 지속적인 신호 (구간 별, 각 600개, 4.4%)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result_classifier(y, pred):\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    accuracy = accuracy_score(y, pred)\n",
    "    precision = precision_score(y, pred, average='macro')\n",
    "    recall = recall_score(y, pred, average='macro')\n",
    "    f1 = f1_score(y, pred, average='macro')\n",
    "    print(f'accuracy: {accuracy:.6f}, precision: {precision:.6f}, recall: {recall:.6f}, f1_score: {f1:.6f}')\n",
    "    print(confusion_matrix(y, pred))\n",
    "    print(classification_report(y, pred))\n",
    "    \n",
    "def print_result_regressor(y, pred):\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    print(f'mse: {mean_squared_error(y, pred):.6f}, r2_score: {r2_score(y, pred):.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.2/0.8, random_state=0)\n",
    "\n",
    "print(f'X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}')\n",
    "print(f'y_train: {y_train.shape}, y_val: {y_val.shape}, y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 혼자 Test 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_pickle('./data/signal/data_1.pkl')\n",
    "\n",
    "def print_result_classifier(y, pred):\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    accuracy = accuracy_score(y, pred)\n",
    "    precision = precision_score(y, pred, average='macro')\n",
    "    recall = recall_score(y, pred, average='macro')\n",
    "    f1 = f1_score(y, pred, average='macro')\n",
    "    print(f'accuracy: {accuracy:.6f}, precision: {precision:.6f}, recall: {recall:.6f}, f1_score: {f1:.6f}')\n",
    "    print(confusion_matrix(y, pred))\n",
    "    print(classification_report(y, pred))\n",
    "    \n",
    "def print_result_regressor(y, pred):\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    print(f'mse: {mean_squared_error(y, pred):.6f}, r2_score: {r2_score(y, pred):.6f}')\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.2/0.8, random_state=0)\n",
    "\n",
    "print(f'X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}')\n",
    "print(f'y_train: {y_train.shape}, y_val: {y_val.shape}, y_test: {y_test.shape}')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1초\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=2)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "print_result_classifier(y_test, clf.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1초\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(penalty='l2')\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "print_result_classifier(y_test, clf.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1초\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "print_result_classifier(y_test, clf.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5분\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "print_result_classifier(y_test, clf.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1분 30초\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "print_result_classifier(y_test, clf.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1분 30초\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('logistic_regression', LogisticRegression()),\n",
    "        ('svc', SVC(kernel='linear')),\n",
    "        ('gaussianNB', GaussianNB())\n",
    "    ],\n",
    "    voting='hard',\n",
    "    weights=[1, 1, 1]\n",
    ")\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "print_result_classifier(y_test, clf.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5초\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=2,\n",
    "                             random_state=0)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "print_result_classifier(y_test, clf.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4초\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = BaggingClassifier(estimator=GaussianNB(),\n",
    "                        n_estimators=10,\n",
    "                        random_state=0)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "print_result_classifier(y_test, clf.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1분\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(random_state=0)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "print_result_classifier(y_test, clf.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18분\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(max_depth=2, learning_rate=0.1, random_state=0)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "print_result_classifier(y_test, clf.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2분 30초\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "clf1 = SVC(kernel='linear', random_state=1)\n",
    "clf2 = GaussianNB()\n",
    "clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('svm', clf1),\n",
    "        ('gnb', clf2)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression())\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "print_result_classifier(y_test, clf.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3초\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "print_result_classifier(y_test, clf.predict(X_test_scaled))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_tn_lda = clf.transform(X_train_scaled)\n",
    "X_te_lda = clf.transform(X_test_scaled)\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_tn_lda, y_train)\n",
    "print_result_classifier(y_test, clf.predict(X_te_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4초\n",
    "from sklearn.cluster import KMeans\n",
    "clf = KMeans(n_clusters=7, init='random', n_init=10, max_iter=100, random_state=0)\n",
    "clf.fit(X)\n",
    "pred = clf.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_counts = pd.DataFrame(pred).value_counts()\n",
    "plt.pie(x=pred_val_counts, labels=pred_val_counts.index, autopct='%1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14초\n",
    "from sklearn.cluster import DBSCAN\n",
    "clf = DBSCAN(eps=0.2)\n",
    "clf.fit(X)\n",
    "pred = clf.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_counts = pd.DataFrame(pred).value_counts()\n",
    "plt.pie(x=pred_val_counts, labels=pred_val_counts.index, autopct='%1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35초\n",
    "from sklearn.mixture import GaussianMixture\n",
    "clf = GaussianMixture(n_components=7, random_state=0)\n",
    "clf.fit(X)\n",
    "pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_counts = pd.DataFrame(pred).value_counts()\n",
    "plt.pie(x=pred_val_counts, labels=pred_val_counts.index, autopct='%1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2초\n",
    "from sklearn.svm import OneClassSVM\n",
    "clf = OneClassSVM(gamma='auto', nu=0.01)\n",
    "clf.fit(X)\n",
    "pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_counts = pd.DataFrame(pred).value_counts()\n",
    "plt.pie(x=pred_val_counts, labels=pred_val_counts.index, autopct='%1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4초\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "clf = LocalOutlierFactor(n_neighbors=7)\n",
    "pred = clf.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_counts = pd.DataFrame(pred).value_counts()\n",
    "plt.pie(x=pred_val_counts, labels=pred_val_counts.index, autopct='%1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1초\n",
    "from sklearn.ensemble import IsolationForest\n",
    "clf = IsolationForest(random_state=0)\n",
    "clf.fit(X)\n",
    "pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_counts = pd.DataFrame(pred).value_counts()\n",
    "plt.pie(x=pred_val_counts, labels=pred_val_counts.index, autopct='%1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "clf = PCA(n_components=7)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "X_tn_pca = clf.transform(X_train_scaled)\n",
    "X_te_pca = clf.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 혼자 Test 해보기 끝\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from scipy import stats\n",
    "# import numpy as np\n",
    "\n",
    "# # 결측치 처리\n",
    "# customer_purchase.fillna(customer_purchase.mean(), inplace=True)\n",
    "\n",
    "# # 이상치 처리\n",
    "# Q1 = customer_purchase.quantile(0.25)\n",
    "# Q3 = customer_purchase.quantile(0.75)\n",
    "# IQR = Q3 - Q1\n",
    "# customer_purchase = customer_purchase[~((customer_purchase < (Q1 - 1.5 * IQR)) |(customer_purchase > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "# # 스케일링\n",
    "# scaler = StandardScaler()\n",
    "# customer_purchase_scaled = scaler.fit_transform(customer_purchase.select_dtypes(include=[np.number]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **모델**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <모델 가이드>\n",
    "- 문제에 적합한 머신러닝 알고리즘을 선택\n",
    "- 모델을 훈련하고 최적화\n",
    "- 모델의 성능을 평가(정확도, 정밀도, 재현율, F1 점수 등 다양한 지표를 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고객의 구매 이력을 기반으로 하는 협업 필터링 모델을 구현합니다.\n",
    "scikit-learn 라이브러리를 사용하여 훈련 데이터와 테스트 데이터를 분할하고, 모델을 훈련 및 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # 데이터 준비\n",
    "# X = customer_behavior.drop('purchase', axis=1)\n",
    "# y = customer_behavior['purchase']\n",
    "\n",
    "# # 데이터 분할\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # 모델 훈련 및 평가\n",
    "# model = RandomForestClassifier(n_estimators=100000000, random_state=420000000)\n",
    "# model.fit(X_train, y_train)\n",
    "# predictions = model.predict(X_test)\n",
    "\n",
    "# print(f\"Accuracy: {accuracy_score(y_test, predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **결론**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <결론 가이드>\n",
    "- 처음 정의한 문제 해결\n",
    "- 문제와 관련된 새로운 사실\n",
    "- 기존 업무 효율화\n",
    "- 데이터셋에 대한 인사이트\n",
    "- 등등\n",
    "\n",
    "여러 관점에서 프로젝트의 결과를 정리하여 최종 결론을 논리적으로 서술"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추천 시스템을 통해 구매 전환율이 예상보다 X% 향상될 것으로 예측합니다.\n",
    "\n",
    "추가 데이터 수집 및 다른 알고리즘의 적용 가능성에 대해서도 탐색합니다.\n",
    "\n",
    "더 정밀한 타겟팅과 개인화된 추천을 위해, 향후에는 고급 기법들을 도입할 계획입니다. 예를 들어, 딥러닝 기반의 추천 시스템이나, 시간에 따라 변화하는 고객의 선호를 반영할 수 있는 동적 모델링 방법들입니다.\n",
    "\n",
    "이 프로젝트를 통해 얻은 인사이트와 모델은 실제 업무 프로세스에 통합될 예정입니다. 예를 들어, 마케팅 캠페인의 타겟팅 전략 수립, 재고 관리 및 물류 계획의 최적화, 신제품 개발의 방향성 결정 등 다양한 분야에서 활용될 수 있습니다.\n",
    "또한, 프로젝트 결과는 내부 리포트와 워크숍을 통해 공유되어, 조직 전반의 데이터 기반 의사결정 문화를 강화하는 데 기여할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_11_7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
