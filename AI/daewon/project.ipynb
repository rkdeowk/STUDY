{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 개요\n",
    "플라즈마 이상 신호를 진단하기 위해 광 신호를 활용하는 센서를 개발 중입니다.\n",
    "\n",
    "![플라즈마 이미지](image/project/plasma.jpg)\n",
    "\n",
    "PMT 소자를 활용하여 플라즈마에서 방출된 photon을 electron으로 변환하여 세기를 측정하는 방식입니다.\n",
    "\n",
    "데이터 형식은 1차원 배열로, 센서에서는 두 가지 형태의 데이터를 생성합니다:\n",
    "1. **Streaming Data**: 초당 10,000,000 포인트를 생성합니다.\n",
    "2. **Trend Data**: 초당 200 포인트를 생성하며, Streaming Data에서 최소값, 최대값, 평균을 50,000 포인트마다 샘플링하여 생성합니다.\n",
    "\n",
    "현재 데이터의 양이 많아서 사람이 수동으로 데이터를 확인하고 있습니다.\n",
    "\n",
    "두 데이터 모두 양이 많아서 사람이 수동으로 확인하기 어렵습니다.\n",
    "\n",
    "이번 교육을 통해 머신러닝/딥러닝을 활용하여 센서 데이터를 학습하여 진단 결과를 도출하는 모델을 개발하고자 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **기획**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <기획 가이드>\n",
    "> #### 현업 적용 문제 정의\n",
    "(공유 가능한 선에서 업무를 소개해 주세요)\n",
    "- **요구사항 확인 :** 현업에서의 분석 요구사항, 요구사항이 나오게 된 배경 등 과 같은 실제 현업의 문제점 작성.\n",
    "- **문제 범위 설정 :** 인텐시브 과정 내 가능한 수준인가, 분석 범위 및 계획 등과 같은 범위를 설정.\n",
    "- **문제 정의 도출 :** 위 내용을 바탕으로 해결하고 싶은 문제(가설) 정의.<br> (main 정의 후 main을 해결하기 위한 sub 문제 2-3개)\n",
    "\n",
    "> #### 데이터 수집 방안 및 사용 데이터 정의\n",
    "- **데이터 확보 방법 :** 사내 DB 추출, 웹데이터 크롤링 등 확보 방법을 작성해 주세요.\n",
    "- **활용 데이터 정의 :** 데이터 소스(사내 시스템명, 외부 사이트 URL 등), 데이터 유형(정형, 비정형_텍스트, 이미지, 영상 등), Feature, 형태(확장자, shape, size, count) 등 데이터에 관한 설명<br>\n",
    "\n",
    "> #### 분석 방향 설정\n",
    "- **분석 시 예상되는 어려움 :** 논리적 추론을 통해 문제를 해결해 나가는 과정에서 짐작되는 어려운 부분을 작성.\n",
    "- **문제 해결을 위한 모델 사용 방법 :** 문제에 적합한 모델을 어떻게 구성해 나갈 것인지 작성."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [배경 설명 & 요구사항 확인]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배경: 온라인 쇼핑몰에서 고객의 구매 이력 데이터를 분석하여 고객별 맞춤형 상품 추천을 제공하고자 합니다.\n",
    "\n",
    "요구사항 확인: 고객의 구매 패턴을 분석하고, 고객별로 관심 있을 만한 상품을 추천하여 구매 전환율을 높이고자 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [문제 범위 설정]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분석 범위는 지난 1년간의 구매 이력 데이터를 활용하여 주요 구매 패턴을 식별하고, 상품 추천 알고리즘을 개발하는 것으로 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [문제 정의 도출]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main 문제 정의: 고객별 구매 이력 데이터를 바탕으로 개인화된 상품 추천 모델을 개발합니다.\n",
    "\n",
    "Sub 문제:\n",
    "\n",
    "고객의 구매 패턴 식별\n",
    "\n",
    "추천 시스템의 정확도 향상\n",
    "\n",
    "추천 시스템의 다양성 및 새로움 증가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [데이터 확보 방법]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 확보 방법: 사내 DB에서 고객의 구매 이력, 상품 정보, 고객 행동 로그 데이터를 추출합니다.\n",
    "\n",
    "---\n",
    "데이터 확보 방법: 자체 개발 중인 사내 센서 SSD에 남는 플라즈마 광 신호 데이터를 추출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [활용 데이터 정의]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 소스: 사내 DB\n",
    "\n",
    "데이터 유형: 정형 데이터(구매 이력, 상품 정보)\n",
    "\n",
    "Feature: 고객 ID, 상품 ID, 구매 날짜, 가격, 카테고리 등\n",
    "\n",
    "형태: CSV 파일, 각 파일은 수만 건의 레코드를 포함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [분석시 예상되는 어려움]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고객별 데이터의 불균형이 심각하여 일부 고객에 대한 과적합이 발생할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [문제 해결을 위한 모델 사용 방법]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "협업 필터링과 콘텐츠 기반 필터링을 결합한 하이브리드 추천 시스템을 구현합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **준비**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <준비 가이드>\n",
    "#### 데이터 수집 및 로드\n",
    "- 문제 해결에 필요한 데이터를 수집 및 로드.\n",
    "\n",
    "#### 데이터 전처리\n",
    "- 결측치 처리, 이상치 처리, feature scale 등 데이터 정제.\n",
    "- 데이터의 품질을 향상시키는 것이 중요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [데이터 수집 및 로드]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사내 DB에서 SQL 쿼리를 사용하여 고객 구매 이력, 상품 정보, 고객 행동 로그 데이터를 추출합니다.\n",
    "데이터는 CSV 형식으로 저장되며, Python의 pandas 라이브러리를 사용하여 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df_signal1 = pd.read_csv('./data/signal/data_1.csv')\n",
    "# df_signal2 = pd.read_csv('./data/signal/data_2.csv')\n",
    "# df_signal3 = pd.read_csv('./data/signal/data_3.csv')\n",
    "# df_signal5 = pd.read_csv('./data/signal/data_5.csv')\n",
    "\n",
    "df = pd.read_csv('./data/signal/data_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [데이터 전처리]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치는 해당 필드의 평균값(연속형 변수)이나 최빈값(범주형 변수)으로 대체합니다.\n",
    "이상치는 IQR(Interquartile Range) 방법을 사용하여 식별하고 처리합니다.\n",
    "모든 수치형 변수는 스케일링을 통해 정규화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "scaler = Normalizer(norm='max')\n",
    "scaler.fit(X_train)\n",
    "X_train_norm = scaler.transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pairs = [('original', X_train, X_test), ('standardization', X_train_std, X_test_std), ('normalization', X_train_norm, X_test_norm)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "for title, x_train, x_test in X_pairs:\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "\n",
    "    print(title)\n",
    "    print(confusion_matrix(y_test, pred))\n",
    "    print(classification_report(y_test, pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from scipy import stats\n",
    "# import numpy as np\n",
    "\n",
    "# # 결측치 처리\n",
    "# customer_purchase.fillna(customer_purchase.mean(), inplace=True)\n",
    "\n",
    "# # 이상치 처리\n",
    "# Q1 = customer_purchase.quantile(0.25)\n",
    "# Q3 = customer_purchase.quantile(0.75)\n",
    "# IQR = Q3 - Q1\n",
    "# customer_purchase = customer_purchase[~((customer_purchase < (Q1 - 1.5 * IQR)) |(customer_purchase > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "# # 스케일링\n",
    "# scaler = StandardScaler()\n",
    "# customer_purchase_scaled = scaler.fit_transform(customer_purchase.select_dtypes(include=[np.number]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <EDA 가이드>\n",
    "- 데이터의 구조, 패턴, 이상치, 상관 관계 등을 파악\n",
    "- 시각화 도구를 사용하여 데이터를 분석\n",
    "- 모델의 성능을 향상시키기 위해 피처를 선택, 변환, 생성\n",
    "- 데이터의 정보를 최대한 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matplotlib과 seaborn 라이브러리를 사용하여 데이터의 분포, 상관 관계를 시각화합니다.\n",
    "고객의 구매 패턴, 상품 카테고리별 판매량 등 주요 인사이트를 도출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # 고객별 구매 빈도 시각화\n",
    "# customer_purchase_frequency = customer_purchase['customer_id'].value_counts()\n",
    "# sns.histplot(customer_purchase_frequency, kde=True)\n",
    "# plt.title('Customer Purchase Frequency')\n",
    "# plt.xlabel('Number of Purchases')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n",
    "\n",
    "# # 상품 카테고리별 판매량\n",
    "# sns.countplot(data=product_info, x='category')\n",
    "# plt.title('Sales by Product Category')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.ylabel('Number of Sales')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 시각화 결과를 통해 다음과 같은 패턴을 확인할 수 있었습니다.\n",
    "\n",
    "`bill_length_mm`과 `bill_depth_mm`로 Scatter plot를 그려볼 시 각 종별로 일부 데이터를 제외하고 군집이 잘 형성됨을 확인하였습니다.\n",
    "\n",
    "- **Adelie:** 다른 펭귄 보다 bill_length가 작고, Chinstrap 펭귄과  bill_depth가 비슷하게 분포한다.\n",
    "- **Chinstrap:** Adelie 펭귄 보다 bill_length가 크고, Gentoo 펭귄과 bill_depth가 비슷하게 분포한다.\n",
    "- **Gentoo:**  Chinstrap 펭귄과 bill_length가 비슷하고, 다른 펭귄 보다 bill_depth가 작게 분포한다.\n",
    "\n",
    "\n",
    "종과 상관없이 수컷 팽귄의 `bill_length`와 `bill_depth`이 암컷보다 선형적으로 커진다는 것을 확인할 수 있었으며,\n",
    "<br>`body_mass`를 통해 Gentoo 펭귄이 다른 종보다 큰 몸집을 갖는다는 것을 확인하였습니다.\n",
    "\n",
    "이 내용을 기반으로 종별 bill_length, bill_depth 등 각 컬럼의 Number Summary를 확인 하고자 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **모델**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <모델 가이드>\n",
    "- 문제에 적합한 머신러닝 알고리즘을 선택\n",
    "- 모델을 훈련하고 최적화\n",
    "- 모델의 성능을 평가(정확도, 정밀도, 재현율, F1 점수 등 다양한 지표를 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고객의 구매 이력을 기반으로 하는 협업 필터링 모델을 구현합니다.\n",
    "scikit-learn 라이브러리를 사용하여 훈련 데이터와 테스트 데이터를 분할하고, 모델을 훈련 및 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # 데이터 준비\n",
    "# X = customer_behavior.drop('purchase', axis=1)\n",
    "# y = customer_behavior['purchase']\n",
    "\n",
    "# # 데이터 분할\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # 모델 훈련 및 평가\n",
    "# model = RandomForestClassifier(n_estimators=100000000, random_state=420000000)\n",
    "# model.fit(X_train, y_train)\n",
    "# predictions = model.predict(X_test)\n",
    "\n",
    "# print(f\"Accuracy: {accuracy_score(y_test, predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **결론**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <결론 가이드>\n",
    "- 처음 정의한 문제 해결\n",
    "- 문제와 관련된 새로운 사실\n",
    "- 기존 업무 효율화\n",
    "- 데이터셋에 대한 인사이트\n",
    "- 등등\n",
    "\n",
    "여러 관점에서 프로젝트의 결과를 정리하여 최종 결론을 논리적으로 서술"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추천 시스템을 통해 구매 전환율이 예상보다 X% 향상될 것으로 예측합니다.\n",
    "\n",
    "추가 데이터 수집 및 다른 알고리즘의 적용 가능성에 대해서도 탐색합니다.\n",
    "\n",
    "더 정밀한 타겟팅과 개인화된 추천을 위해, 향후에는 고급 기법들을 도입할 계획입니다. 예를 들어, 딥러닝 기반의 추천 시스템이나, 시간에 따라 변화하는 고객의 선호를 반영할 수 있는 동적 모델링 방법들입니다.\n",
    "\n",
    "이 프로젝트를 통해 얻은 인사이트와 모델은 실제 업무 프로세스에 통합될 예정입니다. 예를 들어, 마케팅 캠페인의 타겟팅 전략 수립, 재고 관리 및 물류 계획의 최적화, 신제품 개발의 방향성 결정 등 다양한 분야에서 활용될 수 있습니다.\n",
    "또한, 프로젝트 결과는 내부 리포트와 워크숍을 통해 공유되어, 조직 전반의 데이터 기반 의사결정 문화를 강화하는 데 기여할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_11_7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
