{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from skimage.metrics import structural_similarity as ssim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(img, num_images=5):\n",
    "    total_images = len(img)\n",
    "    num_rows = int(np.ceil(total_images / num_images))  # 필요한 행의 수 계산\n",
    "    \n",
    "    # 서브플롯 생성 (num_rows 행과 num_images 열)\n",
    "    fig, axes = plt.subplots(num_rows, num_images, figsize=(num_images * 3, num_rows * 3))\n",
    "    \n",
    "    # 만약 num_rows가 1이라면, axes를 1차원 배열로 처리하도록 설정\n",
    "    if num_rows == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "    \n",
    "    # 이미지 그리기\n",
    "    for i in range(total_images):\n",
    "        row = i // num_images  # 현재 행\n",
    "        col = i % num_images  # 현재 열\n",
    "        axes[row, col].imshow(img[i].squeeze(), cmap='gray')  # 이미지 표시\n",
    "        axes[row, col].set_title(f\"Image {i+1}\")  # 이미지 제목 설정\n",
    "        axes[row, col].axis('off')  # 축 숨기기\n",
    "    \n",
    "    # 남은 빈 서브플롯 숨기기\n",
    "    for i in range(total_images, num_rows * num_images):\n",
    "        row = i // num_images\n",
    "        col = i % num_images\n",
    "        axes[row, col].axis('off')  # 빈 칸은 숨기기\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FDC 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('./data/fdc_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "sensor_data = df_final.iloc[:,5:]\n",
    "sensor_data_scaled = scaler.fit_transform(sensor_data)\n",
    "df_sensor_scaled = pd.DataFrame(sensor_data_scaled, columns=sensor_data.columns)\n",
    "df_fdc_scaled = pd.concat([df_final.iloc[:,:5].reset_index(drop=True), df_sensor_scaled.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라벨 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_fdc_scaled['PASS(1)/FAIL(0)'].values\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = np.load('./data/image_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델\n",
    "\n",
    "1. FDC data → Image 예측\n",
    "\n",
    "2. Image → Scratch 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / Validation / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdc_train, fdc_temp, img_train, img_temp, labels_train, labels_temp = train_test_split(\n",
    "    df_sensor_scaled, image_data, labels, test_size=0.2, random_state=SEED\n",
    ")\n",
    "\n",
    "fdc_val, fdc_test, img_val, img_test, labels_val, labels_test = train_test_split(\n",
    "    fdc_temp, img_temp, labels_temp, test_size=0.25, random_state=SEED  # 0.25 of the remaining 20% = 5% of total\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdc_train.shape, fdc_val.shape, fdc_test.shape, img_train.shape, img_val.shape, img_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. FDC data → Image 예측 모델 학습 (20241027 Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# # FDC 데이터를 이미지 잠재 표현으로 변환하는 인코더\n",
    "# def build_fdc_encoder(input_dim, latent_dim):\n",
    "#     inputs = layers.Input(shape=(input_dim,))\n",
    "#     x = layers.Dense(512, activation='relu')(inputs)\n",
    "#     x = layers.Dense(1024, activation='relu')(x)\n",
    "#     x = layers.Dense(latent_dim, activation='relu')(x)\n",
    "#     x = layers.Reshape((16, 16, 128))(x)  # 잠재 공간 형태로 변환\n",
    "#     return models.Model(inputs, x, name=\"fdc_encoder\")\n",
    "\n",
    "# # 디코더 모델 정의\n",
    "# def build_decoder(latent_shape):\n",
    "#     encoded_input = layers.Input(shape=latent_shape)  # 잠재 공간 입력\n",
    "\n",
    "#     # 업샘플링 단계\n",
    "#     x = layers.Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding='same')(encoded_input)\n",
    "#     x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "#     x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "#     decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "#     return models.Model(encoded_input, decoded, name=\"decoder\")\n",
    "\n",
    "# # 전체 모델 구성\n",
    "# input_dim = 216  # FDC 데이터 차원\n",
    "# latent_dim = 16 * 16 * 128  # 잠재 공간 크기\n",
    "\n",
    "# fdc_encoder = build_fdc_encoder(input_dim, latent_dim)\n",
    "# decoder = build_decoder((16, 16, 128))\n",
    "\n",
    "# fdc_inputs = layers.Input(shape=(input_dim,))\n",
    "# encoded_fdc = fdc_encoder(fdc_inputs)\n",
    "# decoded_image = decoder(encoded_fdc)\n",
    "\n",
    "# # 최종 모델 생성\n",
    "# autoencoder = models.Model(fdc_inputs, decoded_image)\n",
    "# autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# # 모델 학습\n",
    "# autoencoder.fit(fdc_train, img_train, epochs=1000, batch_size=32, validation_data=(fdc_val, img_val))\n",
    "\n",
    "# autoencoder.save('./data/model/autoencoder_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder = tf.keras.models.load_model(f'./data/model/autoencoder_model.keras')\n",
    "# predicted_images = autoencoder.predict(fdc_test)\n",
    "\n",
    "# visualize_images(img_test)\n",
    "# visualize_images(predicted_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. FDC data → Image 예측 모델 학습 (20241020 Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encoder 모델: 입력 이미지를 잠재 공간으로 압축\n",
    "# def build_encoder(input_dim):\n",
    "#     model = tf.keras.Sequential()\n",
    "#     model.add(layers.Dense(256, input_dim=input_dim))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "#     model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    \n",
    "#     model.add(layers.Dense(512))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "#     model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    \n",
    "#     model.add(layers.Dense(1024))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "#     model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    \n",
    "#     model.add(layers.Dense(2048))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "#     model.add(layers.BatchNormalization(momentum=0.8))\n",
    "\n",
    "    \n",
    "#     # 잠재 공간 (저차원 공간) 출력\n",
    "#     model.add(layers.Dense(64))  # 잠재 공간의 크기를 64로 설정\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# # Decoder 모델: 잠재 공간에서 128x128 이미지를 복원\n",
    "# def build_decoder(latent_dim):\n",
    "#     model = tf.keras.Sequential()\n",
    "\n",
    "#     model.add(layers.Dense(2048))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "#     model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    \n",
    "#     model.add(layers.Dense(1024, input_dim=latent_dim))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "#     model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    \n",
    "#     model.add(layers.Dense(512))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "#     model.add(layers.Dense(256))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "#     # 128x128 이미지로 복원\n",
    "#     model.add(layers.Dense(128 * 128, activation='sigmoid'))  # 이미지 픽셀 값이 0-1 범위이므로 sigmoid 사용\n",
    "#     model.add(layers.Reshape((128, 128, 1)))\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# # Autoencoder 모델: Encoder와 Decoder를 연결\n",
    "# def build_autoencoder(input_dim, latent_dim):\n",
    "#     encoder = build_encoder(input_dim)\n",
    "#     decoder = build_decoder(latent_dim)\n",
    "    \n",
    "#     inputs = layers.Input(shape=(input_dim,))\n",
    "#     encoded = encoder(inputs)\n",
    "#     decoded = decoder(encoded)\n",
    "    \n",
    "#     autoencoder = tf.keras.Model(inputs, decoded)\n",
    "#     autoencoder.compile(optimizer='adam', loss='mse')  # Autoencoder에서는 MSE(평균 제곱 오차)를 사용\n",
    "#     return autoencoder\n",
    "\n",
    "# # 하이퍼파라미터\n",
    "# tf.random.set_seed(SEED)\n",
    "# input_dim = fdc_train.shape[1]  # FDC 데이터의 차원\n",
    "# latent_dim = 64  # 잠재 공간의 크기\n",
    "# epochs = 1000\n",
    "# batch_size = 32\n",
    "\n",
    "# # 모델 빌드\n",
    "# autoencoder = build_autoencoder(input_dim, latent_dim)\n",
    "\n",
    "# # 학습 함수\n",
    "# def train_autoencoder(epochs, batch_size):\n",
    "#     autoencoder.fit(fdc_train, img_train, epochs=epochs, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# # Autoencoder 학습 시작\n",
    "# train_autoencoder(epochs, batch_size)\n",
    "\n",
    "# # 모델 저장\n",
    "# autoencoder.save(f'./data/model/autoencoder_model_{epochs}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "\n",
    "autoencoder = tf.keras.models.load_model(f'./data/model/autoencoder_model_{epochs}.keras')\n",
    "predicted_images = autoencoder.predict(fdc_test)\n",
    "\n",
    "visualize_images(img_test)\n",
    "visualize_images(predicted_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_images에서 마지막 차원(채널) 제거\n",
    "predicted_images_squeezed = np.squeeze(predicted_images)  # (53, 128, 128, 1) -> (53, 128, 128)\n",
    "\n",
    "# 두 이미지 간의 SSIM 계산 (data_range 설정)\n",
    "ssim_value = ssim(img_test, predicted_images_squeezed, multichannel=True, data_range=1)\n",
    "print(f\"SSIM: {ssim_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Image 분류 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 외곽 부분을 마스킹하는 함수 정의 (원형 마스크 사용)\n",
    "def create_edge_mask(image, radius):\n",
    "    h, w = image.shape[:2]\n",
    "    center = (int(w / 2), int(h / 2))\n",
    "    max_radius = min(center) - 2  # 이미지 경계 안에 들어가도록 반지름 설정\n",
    "    mask = np.zeros((h, w), dtype=np.uint8)  # 마스크를 8비트 정수로 생성\n",
    "    \n",
    "    # 원형 마스크 생성 (두께는 외곽 영역의 범위를 조절)\n",
    "    cv2.circle(mask, center, max_radius, 1, thickness=radius)  # 마스크 값 1로 설정\n",
    "    return mask\n",
    "\n",
    "# 이미지 데이터 (img_train을 불러온 상태라 가정)\n",
    "image = img_train[0]  # 첫 번째 훈련 이미지 사용\n",
    "\n",
    "# 다양한 radius 값으로 마스크를 생성하고 시각적으로 확인\n",
    "radius_values = [1,5, 10, 15, 20, 50, 100]  # 다양한 반경 값을 설정\n",
    "fig, axes = plt.subplots(1, len(radius_values), figsize=(15, 5))\n",
    "\n",
    "for i, radius in enumerate(radius_values):\n",
    "    # 마스크 생성\n",
    "    mask = create_edge_mask(image, radius=radius)\n",
    "    \n",
    "    # 마스크를 이미지에 적용하여 시각적으로 비교\n",
    "    masked_image = cv2.bitwise_and(image.squeeze().astype(np.uint8), image.squeeze().astype(np.uint8), mask=mask)\n",
    "    \n",
    "    # 이미지 출력\n",
    "    axes[i].imshow(masked_image, cmap='gray')\n",
    "    axes[i].set_title(f\"Radius: {radius}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 외곽 부분을 마스킹하는 함수 정의 (원형 마스크 사용)\n",
    "def create_edge_mask(image, radius=50):\n",
    "    h, w = image.shape[:2]\n",
    "    center = (int(w / 2), int(h / 2))\n",
    "    max_radius = min(center) - 2  # 이미지 경계 안에 들어가도록 반지름 설정\n",
    "    mask = np.zeros((h, w), dtype=np.uint8)  # 마스크를 uint8 형식으로 생성\n",
    "\n",
    "    # 원형 마스크 생성 (두께는 외곽 영역의 범위를 조절)\n",
    "    cv2.circle(mask, center, max_radius, 1, thickness=radius)  # 1로 채운 원형 마스크\n",
    "    return mask\n",
    "\n",
    "# 모든 이미지에 마스크 적용\n",
    "def apply_mask_to_images(images, mask_radius=50):\n",
    "    masked_images = []\n",
    "    for image in images:\n",
    "        mask = create_edge_mask(image.squeeze(), radius=mask_radius)\n",
    "        \n",
    "        # 이미지가 0~1로 스케일링된 경우 0~255 범위로 변환\n",
    "        image_uint8 = (image.squeeze() * 255).astype(np.uint8)\n",
    "        \n",
    "        # 마스크 적용\n",
    "        masked_image = cv2.bitwise_and(image_uint8, image_uint8, mask=mask)\n",
    "        masked_images.append(masked_image)\n",
    "    return np.array(masked_images)\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터 각각에 마스크 적용\n",
    "masked_train = apply_mask_to_images(img_train)\n",
    "masked_val = apply_mask_to_images(img_val)\n",
    "masked_test = apply_mask_to_images(img_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN 분류 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델 생성\n",
    "def build_edge_classification_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Convolutional layer로 특징 추출\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Flatten하여 Dense Layer에 연결\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    \n",
    "    # 이진 분류를 위한 출력층\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))  # 이진 분류\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 입력 이미지의 크기 (128x128 크기의 흑백 이미지)\n",
    "input_shape = (128, 128, 1)\n",
    "cnn = build_edge_classification_model(input_shape)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "# 훈련 데이터를 이용해 모델 학습\n",
    "cnn.fit(masked_train, labels_train, \n",
    "          epochs=epochs, \n",
    "          batch_size=32, \n",
    "          validation_data=(masked_val, labels_val))\n",
    "\n",
    "# 모델 저장\n",
    "cnn.save(f'./data/model/cnn_model_{epochs}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "\n",
    "cnn = tf.keras.models.load_model(f'./data/model/cnn_model_{epochs}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터로 모델 성능 평가\n",
    "test_loss, test_acc = cnn.evaluate(masked_test, labels_test)\n",
    "print(f\"테스트 정확도: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_predicted_images = apply_mask_to_images(predicted_images)\n",
    "predicted_loss, predicted_acc = cnn.evaluate(masked_predicted_images, labels_test)\n",
    "print(f\"테스트 정확도: {predicted_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 이미지와 비교하여 시각적으로 평가\n",
    "def compare_original_and_predicted(original_images, predicted_images, masked_images):\n",
    "    fig, axes = plt.subplots(3, len(original_images), figsize=(15, 10))\n",
    "    \n",
    "    for i in range(len(original_images)):\n",
    "        # 원본 이미지 출력\n",
    "        axes[0, i].imshow(original_images[i].squeeze(), cmap='gray')\n",
    "        axes[0, i].set_title(f\"Original Image {i+1}\")\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # 예측된 이미지 출력\n",
    "        axes[1, i].imshow(predicted_images[i].squeeze(), cmap='gray')\n",
    "        axes[1, i].set_title(f\"Predicted Image {i+1}\")\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # 마스크된 예측 이미지 출력\n",
    "        axes[2, i].imshow(masked_images[i].squeeze(), cmap='gray')\n",
    "        axes[2, i].set_title(f\"Masked Predicted {i+1}\")\n",
    "        axes[2, i].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# 원본 이미지와 예측된 이미지를 비교\n",
    "compare_original_and_predicted(img_test[5:10], predicted_images[5:10], masked_predicted_images[5:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
