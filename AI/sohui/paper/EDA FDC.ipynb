{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rkdeo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fdc = pd.read_excel('./data/raw/Sensor_Data_DSS_반출.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동일값으로만 이루어진 열 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "같은 값으로 이루어진 열과 값: {}\n"
     ]
    }
   ],
   "source": [
    "def find_constant_columns(df):\n",
    "    constant_columns = {}\n",
    "    for col in df.columns:\n",
    "        if df[col].nunique() == 1:  \n",
    "            constant_columns[col] = df[col].iloc[0] \n",
    "    return constant_columns\n",
    "\n",
    "constant_columns = find_constant_columns(df_fdc)\n",
    "print(\"같은 값으로 이루어진 열과 값:\", constant_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 값이 NaN인 행의 개수: 243\n"
     ]
    }
   ],
   "source": [
    "def count_all_nan_rows(df):\n",
    "    nan_rows_count = df.iloc[:, 5:].isna().all(axis=1).sum()\n",
    "    print(f\"모든 값이 NaN인 행의 개수: {nan_rows_count}\")\n",
    "\n",
    "count_all_nan_rows(df_fdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 276) → (1066, 276)\n"
     ]
    }
   ],
   "source": [
    "def remove_all_nan_rows(df):\n",
    "    nan_rows = df.iloc[:, 5:].isna().all(axis=1)\n",
    "    df_cleaned = df[~nan_rows]\n",
    "    return df_cleaned\n",
    "\n",
    "df_fdc_remove_missing = remove_all_nan_rows(df_fdc)\n",
    "print(f'{df_fdc.shape} → {df_fdc_remove_missing.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 값이 NaN인 행의 개수: 0\n"
     ]
    }
   ],
   "source": [
    "count_all_nan_rows(df_fdc_remove_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_with_missing_values(df):\n",
    "    missing_values = df.isnull().sum()  \n",
    "    missing_columns = missing_values[missing_values > 0]\n",
    "    return missing_columns\n",
    "\n",
    "missing_columns = get_columns_with_missing_values(df_fdc_remove_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제거 후 남은 열: Index(['ID', 'EQUIP_ID', 'DATE_TIME', 'YVALUE', 'PASS(1)/FAIL(0)', 'X38_05',\n",
      "       'X30_10', 'X34_02', 'X53_02', 'X52_10',\n",
      "       ...\n",
      "       'X39_13', 'X41_13', 'X50_13', 'X53_13', 'X57_13', 'X58_13.1', 'X36_13',\n",
      "       'X45_13', 'X51_13', 'X34_13'],\n",
      "      dtype='object', length=221)\n"
     ]
    }
   ],
   "source": [
    "def remove_columns_with_missing_values(df, missing_columns):\n",
    "    df_cleaned = df.drop(columns=missing_columns.index)\n",
    "    return df_cleaned\n",
    "\n",
    "df_fdc_cleaned = remove_columns_with_missing_values(df_fdc_remove_missing, missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_image_list = ['ID_1231', 'ID_1233', 'ID_1239', 'ID_1241', 'ID_1244', 'ID_1245','ID_1309']\n",
    "df_final = df_fdc_cleaned[~df_fdc_cleaned['ID'].isin(no_image_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =StandardScaler()\n",
    "\n",
    "sensor_data = df_final.iloc[:,5:]\n",
    "sensor_data_scaled = scaler.fit_transform(sensor_data)\n",
    "df_sensor_scaled = pd.DataFrame(sensor_data_scaled, columns=sensor_data.columns)\n",
    "df_fdc_scaled = pd.concat([df_final.iloc[:,:5].reset_index(drop=True), df_sensor_scaled.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라벨 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_fdc_scaled['PASS(1)/FAIL(0)'].values\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 데이터 추출 및 배열 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_filenames(image_folder, image_ids):\n",
    "    image_filenames = []\n",
    "    for image_id in image_ids:\n",
    "        image_path = os.path.join(image_folder, f\"{image_id}.png\")\n",
    "        if os.path.exists(image_path): \n",
    "            image_filenames.append(image_path) \n",
    "        else:\n",
    "            print(f\"파일을 찾을 수 없습니다: {image_id}\")\n",
    "    return image_filenames\n",
    "\n",
    "image_folder = './data/image'\n",
    "image_ids = df_final['ID']\n",
    "image_filenames = get_image_filenames(image_folder, image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_filenames의 순서와 df_final['ID']의 순서가 모두 일치합니다.\n"
     ]
    }
   ],
   "source": [
    "def compare_image_order():\n",
    "    image_ids = [os.path.basename(filename).split('.')[0] for filename in image_filenames]\n",
    "    comparison_result = df_final['ID'].astype(str) == image_ids\n",
    "\n",
    "    if comparison_result.all():\n",
    "        print(\"image_filenames의 순서와 df_final['ID']의 순서가 모두 일치합니다.\")\n",
    "    else:\n",
    "        print(\"일치하지 않는 항목이 있습니다.\")\n",
    "        mismatch_indices = comparison_result[comparison_result == False].index\n",
    "        print(f\"일치하지 않는 인덱스: {mismatch_indices.tolist()}\")\n",
    "\n",
    "compare_image_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_numpy(file_path):\n",
    "    image = Image.open(file_path).convert('L')  # Convert image to grayscale\n",
    "    image = image.resize((128, 128))\n",
    "    return np.array(image) / 255.0\n",
    "\n",
    "image_data = np.array([image_to_numpy(file) for file in image_filenames])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train, Validation, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fdc_temp, X_fdc_val, X_img_temp, X_img_val, y_temp, y_val = train_test_split(\n",
    "    df_sensor_scaled, image_data, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_fdc_train, X_fdc_test, X_img_train, X_img_test, y_train, y_test = train_test_split(\n",
    "    X_fdc_temp, X_img_temp, y_temp, test_size=0.25, random_state=42\n",
    ")  # 여기서 test_size=0.25는 validation+test의 20% 중 25%를 test로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델\n",
    "\n",
    "1. FDC data → Image 예측\n",
    "\n",
    "2. Image → Scratch 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 조건부 생성 모델(Conditional Generative Models)\n",
    "조건부 생성적 적대 신경망(Conditional GAN, cGAN):\n",
    "\n",
    "개념: 숫자 데이터를 조건(condition)으로 받아 이미지를 생성하는 모델입니다.\n",
    "장점: 입력 데이터의 변동이 작더라도, 생성기(Generator)가 다양한 이미지를 생성할 수 있습니다.\n",
    "구성:\n",
    "생성기(Generator): 숫자 데이터와 랜덤 노이즈를 입력으로 받아 이미지를 생성합니다.\n",
    "판별기(Discriminator): 실제 이미지와 생성된 이미지를 구분하며, 이때 숫자 데이터를 함께 입력으로 받습니다.\n",
    "조건부 변분 오토인코더(Conditional Variational Autoencoder, CVAE):\n",
    "\n",
    "개념: 숫자 데이터를 조건으로 사용하여 이미지를 생성하는 오토인코더 구조입니다.\n",
    "장점: 잠재 공간(Latent Space)을 활용하여 데이터의 다양성을 표현할 수 있습니다.\n",
    "\n",
    "3. 멀티모달 딥러닝(Multimodal Deep Learning)\n",
    "추가 입력 데이터 활용:\n",
    "만약 가능하다면, 이미지에 영향을 줄 수 있는 다른 변수나 센서 데이터 등을 추가로 수집하여 모델의 입력으로 사용합니다.\n",
    "모달리티 간의 상호작용 학습:\n",
    "숫자 데이터와 다른 형태의 데이터를 함께 입력하여 모델이 복잡한 패턴을 학습하도록 합니다.\n",
    "4. 주의 메커니즘(Attention Mechanism) 도입\n",
    "Self-Attention 또는 Cross-Attention:\n",
    "모델이 입력 데이터의 중요한 부분에 집중하여 출력 이미지를 생성하도록 합니다.\n",
    "Transformers 기반 모델:\n",
    "GPT나 Vision Transformer(ViT) 등을 활용하여 이미지 생성에 적용할 수 있습니다.\n",
    "6. 중간 표현 학습\n",
    "Autoencoder를 통한 특성 추출:\n",
    "숫자 데이터를 입력으로 중간 표현을 학습하고, 이를 기반으로 이미지를 생성합니다.\n",
    "Decoder 네트워크 사용:\n",
    "중간 표현에서 이미지를 복원하거나 생성하는 디코더를 설계합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
